# Kaggle Notebooks

This repo contains Kaggle notebooks written by me.

# Descriptions

- `kaggle-nlp-disaster.ipynb`
  - Used a simple bidirectional LSTM model.
  - Competition link: [https://www.kaggle.com/competitions/nlp-getting-started](https://www.kaggle.com/competitions/nlp-getting-started)
- `kaggle-nlp-disaster-bert.ipynb`
  - Used Bertweet model with fine-tuning.
  - Competition link: [https://www.kaggle.com/competitions/nlp-getting-started](https://www.kaggle.com/competitions/nlp-getting-started)
- `kaggle-nlp-ell-distilbert-colab.ipynb`
  - Used DistilBERT model with fine-tuning.
  - Competition link: [https://www.kaggle.com/competitions/feedback-prize-english-language-learning](https://www.kaggle.com/competitions/feedback-prize-english-language-learning)
- `kaggle-nlp-ell-distilbert-kaggle.ipynb`
  - The same strategy with the above notebook, but changed some logics to make it run on the kaggle offline notebook.
  - Competition link: [https://www.kaggle.com/competitions/feedback-prize-english-language-learning](https://www.kaggle.com/competitions/feedback-prize-english-language-learning)
- `tps-2022-aug.ipynb`
  - Used a five-layer neural network model.
  - Competition link: [https://www.kaggle.com/competitions/tabular-playground-series-aug-2022](https://www.kaggle.com/competitions/tabular-playground-series-aug-2022)
